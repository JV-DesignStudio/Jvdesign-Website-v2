User's request for the contents of the file: /portfolio-website/portfolio-website/public/robots.txt

User's specification for the file:
The file is used to manage web crawler access to the website. It specifies which parts of the site should not be accessed by search engines.

Contents for robots.txt:

User-agent: *
Disallow: /src/
Disallow: /public/
Disallow: /node_modules/
Disallow: /package.json
Disallow: /tsconfig.json
Disallow: /vite.config.ts
Disallow: /README.md
Disallow: /gitignore